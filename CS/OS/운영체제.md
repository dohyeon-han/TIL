# 운영체제

## 운영체제의 역할
- 컴퓨터 시스템은 대게 하드웨어, 운영체제, 응용 프로그램, 사용자로 구분할 수 있다.
- 운영체제는 하드웨어와 응용 프로그램 간의 제어를 통해 사용자의 편의성을 향상(GUI, 음성인식, 터치스크린 등)시키고 리소스를 효과적으로 할당한다.

## 인터럽트
- 운영체제는 각 장치 컨트롤러마다 장치 드라이버가 있고 컨트롤러가 작동하게 일관된 인터페이스를 제공한다. 장치 컨트롤러는 CPU의 처리를 받기 위해 서로 경쟁한다.
- 장치 컨트롤러가 작업을 완료하면 인터럽트를 통해 장치 드라이버에게 상태 정보를 반환한다.

### 인터럽트 처리 순서
- 하드웨어는 CPU에 신호를 보내 인터럽트를 발생시킨다
- CPU는 하던 일을 중단하고 현재 상태를 저장한다.
- 인터럽트의 원인을 확인하고 인터럽트 벡터를 통해 인터럽트 서비스 루틴을 호출한다.
- 인터럽트를 처리한다.
- 인터럽트에서 복귀하여 중단된 작업을 처리한다.

### 인터럽트 벡터
- 인터럽트는 굉장히 빈번하게 실행된다. 이를 빠르게 처리하기 위해 필요한 인터럽트 루틴에 대한 주소를 미리 지정하여 처리한다.

### 인터럽트가 발생하는 이유
- 키보드 입력 같은 I/O 연산은 CPU의 속도에 비해 훨씬 느리다. 따라서 CPU를 효과적으로 사용하기 위해 인터럽트를 활용한다.

## 저장 구조
- CPU가 명령을 실행하려면 메모리에 프로그램이 적재되어야 한다. 범용 컴퓨터는 대부분의 프로그램을 메인 메모리에 적재한다. 이 메인 메모리는 주로 DRAM으로 만든다.
- RAM은 휘발성이므로 영구적으로 데이터를 보관할 수 없다. 또한 비싸기 때문에 많은 용량이 크지 않아 보조저장장치로 하드 디스크 드라이브(HDD)와 비휘발성 메모리(NVM)를 사용한다.
- DRAM과 디스크는 CPU에 비해 속도가 느리다. 이 격차를 줄이기 위해 캐시를 사용한다. 캐시는 휘발성 메모리로 자주 사용하는 데이터를 캐시에 복사해 두면 평균 메모리 접근 시간을 아낄 수 있다.

## 운영체제의 작동

### 멀티 프로그래밍과 멀티 태스킹
- 하나의 프로그램이 항상 CPU를 사용하고 있지는 않다. OS가 스케줄링을 통해 프로세스를 스케줄링하고 차례대로 CPU에 할당 받도록하여 CPU의 이용률을 높이는 것을 멀티 프로그래밍이라고 한다.
- 멀티 태스킹은 멀티 프로그래밍의 확장이다. 프로세스 간의 전환을 자주 발생시켜 CPU가 짧은 시간 동안 여러 프로세스를 번갈아가며 실행하는 것을 멀티 태스킹이라고 한다.

### 멀티 모드
- 운영체제는 잘못된 프로그램에 의해 다른 프로그램 혹은 운영체제가 잘못 실행되지 않도록 막아야 한다. 이를 위해 유저 모드, 커널 모드로 연산이 수행되는 위치를 나눈다.
- 트랩이나 인터럽트가 발생하면 커널 모드로 전환되고 운영체제가 컴퓨터의 제어를 얻게 된다. 
- 커널 모드에서만 수행되는 명령을 특권 명령이라고 하는데, 커널 모드로의 전환, I/O제어, 인터럽트 관리 등이 있다.

## 시스템 콜
- 하드웨어에 의한 인터럽트도 있지만 소프트웨어에 의한 인터럽트도 존재한다. 이를 trap이라한다.
    - Trap
        - Exception : 0나누기, 잘못된 기계어, 잘못된 메모리 접근
        - System call : 커널 모드로의 전환이 필요할 때
- 프로세스에서 커널 모드의 명령이 필요하면 시스템 콜을 호출한다. 작업을 모두 완료하면 OS는 커널 모드에서 유저 모드로 전환한다.

## 프로세스
- 프로세스는 메모리에 할당되어 실행되고 있는 프로그램을 의미한다.
 
### 프로세스 제어 블록
- 각 프로세스는 운영체제에서 프로세스 제어 블록(Process control block, PCB)에 의해 표현된다
- 프로세스 상태, 프로그램 카운터, 프로세스 번호 등 프로세스와 연관된 여러 정보를 담고 있다.

### 컨텍스트 스위치
- 인터럽트 혹은 시스템 콜이 실행되면 OS는 CPU에 실행되고 있는 작업을 뺏어 커널 루틴을 실행한다. 이 과정에서 PCB에 현재의 문맥을 저장하고 커널 작업이 끝나면 PCB를 통해 끊겼던 프로세스의 상태를 다시 복구하는데 이것을 컨텍스트 스위치라고한다.
- 이런 작업에는 진행되는 동안 시스템은 다른 작업을 할 수 없으므로 오버헤드가 발생한다.

### 프로세스 간 통신(Interprocesss Communicaiton)
- 기본적으로 프로세스는 다른 프로세스와 데이터를 공유하지 않는다. 따라서 다른 프로세스의 자원에 접근하려면 프로세스 간 통신(IPC)를 사용해야
    - Message passing : 커널을 통해 데이터를 교환한다. 커널 모드로 전환이 필요하기 때문에 컨택스트 스위칭이 일어나 오버헤드가 발생한다.
    - Shared memory : 두 프로세스 사이에 공유 영역을 설정해 데이터를 교환한다. 같은 영역을 사용하기 때문에 동기화가 필요하다.

## 스레드
- CPU 이용의 기본 단위이다. 
- 기존의 프로세스와 같은 일을 하는 프로세스를 생성하면 많은 오버헤드가 발생하기 때문에 스레드를 생성하는 것이 더 효율적이다.

### 장점
- 병렬로 스레드가 실행되므로 응답성이 뛰어나다.
- 같은 프로세스 내에서 다른 스레드와 자원들을 공유하기 때문에 컨텍스트 스위칭 없이 자원을 효과적을 사용할 수 있다.
- 멀티 스레드는 새 프로세스의 생성 없이 하나의 프로세스에서 여러가지 작업을 가능하게 한다.

### 단점
- 자원을 공유하기 때문에 동기화 문제가 발생한다.

### 스레드 풀
- 스레드를 새로 생성하는 것은 시간이 오래 걸린다. 또한 스레드를 무한정 생성하면 시스템의 자원이 고갈된다. 이를 해결하기 위해 프로세스를 시작할 때 일정한 수의 스레드를 미리 만들어두고 재사용한다. 이처럼 스레드를 미리 생성하여 보관하는 곳을 스레드 풀이라고 한다.

## CPU 스케줄링
- 멀티 프로그래밍에서 프로세스는 순서대로 CPU에 할당된다. 스케줄링 알고리즘을 통해 최선의 프로세스 순서를 정하는 것이 중요하다.

### 선점 및 비선점 스케줄링
- 실행 중인 프로세스를 빼앗는다면 선점 그렇지 않으면 비선점 스케줄링이다.

### 선입 선처리 스케줄링(First-Come First-Served, FCFS)
- 가장 간단한 알고리즘으로 프로세스가 준비 큐에 먼저 들어오는 순서대로 CPU에 할당된다.
- 하지만 CPU 버스트 길이가 긴 프로세스가 먼저 할당되면, 다른 프로세스들은 긴 시간을 기다려야 한다. 이를 호위 효과(convey effect)라고 한다.

### 최단 작업 우선 스케줄링(Shortest-Job-First, SJF)
 - 실행 시간이 가장 짧은 프로세스가 먼저 실행되는 알고리즘이다.
 - 평균 대기 시간이 최적인 알고리즘이나 CPU 버스트 길이를 정확하게 예측할 수는 없어서 예측 값으로 구현한다.
 - CPU 버스트 길이가 긴 프로세스의 경우 계속 CPU의 할당을 받지 못할 수도 있다. 이를 기아 상태(starvation)라고 한다.

### 라운드 로빈 스케줄링(Round-Robin, RR)
- 일정 시간 동안만 CPU를 사용한 후 준비 큐의 맨 뒤로 이동하는 방식의 알고리즘이다.
- 공평하게 프로세스를 할당할 수 있지만, 각 프로세스에 할당하는 시간을 길게 잡으면 FCFS와 차이가 없게 되고, 짧게 잡으면 컨택스트 스위칭으로 인해 오버헤드가 커진다.

### 우선 순위 스케줄링(Priority Scheduling)
- 각 프로세스를 우선순위에 따라 CPU에 할당한다. SJF 알고리즘은 우선 순위 스케줄링에 해당한다.
- 이 알고리즘 역시 낮은 우선 순위로 인해 기아 상태가 발생할 수 있으므로 노화(aging)를 적용하여 대기 시간이 늘어날수록 우선 순위를 높인다.

## 동기화
- 프로세스나 스레드는 병렬 혹은 병행하여 실행될 때, 특정 자원에 접근 및 실행 결과가 발생한 순서에 영향을 받는 것을 경쟁 상황(race condition)이라고 한다.
- 이런 상황이 발생하면 공유 변수에 예상치 못한 변화가 발생할 수 있고 이를 해결하기 위해 동기화가 필요하다.

### 해결 방법
1. 뮤텍스 락(Mutex Locks)
- 임계 구역에 진입하기 위해서는 반드시 락을 획득하고 빠져나올 때는 락을 반환하여 하나의 프로세스만 임계 구역에 진입하도록 하는 동기화 방법이다.
- 락은 얻고 반환하는 함수는 원자적으로 실행되어야 한다.
- while문을 이용하여 구현할 경우 대기 프로세스는 락을 얻을 때까지 while에 갖혀있어 바쁜 대기(busy wating)를 해야한다. 이 상태를 스핀락(spinlock)이라고 한다. 하지만 컨텍스트 스위칭이 없으므로 임계구역이 짧다면 유용하게 활용할 수 있다.

2. 세마포(Semaphores)
- 임계 구역에 진입할 수 있는 프로세스의 수를 세마포 값으로 정해서 관리할 수 있다.
- 이때 세마포의 값이 0과 1만을 값으로 가질 수 있다면 이진 세마포, 그 외에는 카운팅 세마포라고 하는데 이진 세마포는 뮤텍스 락과 유사하게 동작한다.
- 뮤텍스 락과 마찬가지로 세마포 값을 조작하는 함수는 원자적으로 실행되어야 한다.

3. 모니터(Moniters)
- 뮤텍스 락과 세마포가 동기화를 위해 효과적으로 쓰일 순 있지만, 프로그래머가 잘못된 프로그래밍을 하면 전체 프로세스에 악영향을 줄 수 있다.
- 이를 위해 프로그래밍 언어 수준에서 제공해주는 동기화 도구를 모니터라고하며 대표적으로 java가 있다.

## 교착 상태(Deadlocks)
- 멀티 프로그래밍 환경에서 여러 스레드가 한정된 자원을 사용하기 위해 서로 경쟁한다. 한 스레드가 자원을 요청했을 때, 그 자원을 사용할 수 없는 상황이면 대기 상태로 들어간다. 이때 서로의 자원을 얻기 위해 대기 상태에 들어가고 그 상태를 변경시킬 수 없는 상황을 교착 상태라고 한다.

### 교착 상태 조건
- 다음 네 가지 조건이 동시에 성립될 때 교착 상태에 빠진다.

1. 상호 배제(mutual exclusion)
    - 자원을 한 번에 한 스레드만 사용할 수 있다. 다른 스레드가 그 자원을 요청하면 요청 스레드는 자원이 방출될 때까지 지연되어야 한다.

2. 점유하며 대기(hold-and-wait)
    - 스레드가 최소한 하나의 자원을 점유한 채, 다른 스레드의 점유된 자원을 추가로 얻기 위해 반드시 대기해야 한다.

3. 비선점(no preemption)
    - 다른 스레드가 선점하고 있는 자원을 강제로 빼앗을 수 없다.

4. 순환 대기(circular wait)
    - 스레드가 요청하는 자원의 방향이 순환하여야 한다.
    - 스레드 A, B, C가 있으면 A는 B가 점유하고 있는 자원을, B는 C의 자원을, C는 A의 자원을 요청하면 순환 대기가 발생한다.

### 해결 방법
1. 무시
- 교착 상태가 발생하여도 무시하고 발생하지 않은 척한다.

2. 예방
- 교착 상태 조건 중 최소한 하나가 성립하지 않도록 보장한다.
- 하지만 각 조건 별로 단점이 존재한다.
    1. 상호 배제
        - 자원에 동시에 접근하면 동기화 문제가 발생한다.
    2. 점유하며 대기
        - 점유를 못하게 할 경우, 인기있는 자원이 여러개 필요한 스레드는 무한정 대기해야 한다.
    3. 비선점
        - 뮤텍스 락, 세마포 같은 선점을 할 수 없는 자원이 존재한다.
    4. 순환 대기
        - 한 가지 방법으로 스레드의 순서를 정해 오름차순으로 자원을 요청하도록 하는 방법이 있다. 하지만 모든 스레드를 순서대로 관리하는 것은 어렵고 기아 상태가 발생할 수 있다.

3. 회피
- 자원을 할당하기 전에 각 스레드가 요청할 수 있는 최대 자원의 수를 분석하여 교착상태에 빠질 수 있는지 확인하고 할당한다.
- 은행원 알고리즘을 이용해 확인할 수 있다.
- 자원의 이용률이 낮아진다.

4. 회복
- 교착 상태가 되도록 허용한 다음 복구시킨다.
    #### 스레드 종료
    1. 교착 상태 스레드를 모두 중지
        - 그 동안의 계산을 처음부터 다시 시작해야하므로 그 비용이 크다.
    2. 교착 상태가 제거될 때까지 한 스레드씩 종료
        - 한 스레드를 중지시킬 때마다 교착 상태를 확인해야 하므로 오버헤드를 유발한다.

    #### 자원 선점
    - 세 가지 사항을 고려해야 한다.
    1. 희생자 선택
        - 스레드 종료, 실행한 시간 같은 비용이 최소화되도록 선점의 순서를 정해야한다.
    2. 후퇴(rollback)
        - 스레드로부터 필요한 자원을 선점하면 그 스레드는 정상적인 실행을 할 수 없는데, 어느 정도까지 후퇴를 시켜야하는지 판단해야한다.
    3. 기아 상태(starvation)
        - 동일한 스레드가 항상 선택되지 않도록 보장해야한다.

## 메모리 할당
- 프로세스들이 메모리에 적재되면 그 크기만큼 공간을 차지하게 된다. 

### 논리(가상) 주소, 물리 주소
- 코드를 실행하기 위해서는 반드시 메모리에 있어야한다. 하지만 모든 프로세스를 메모리에 할당하기에는 공간이 부족하다.
- 프로세스가 실행하는데 필요한 메모리는 실제보다 작다는 점을 이용해 필요한 부분만 실제 메모리에 할당한다.
- 이를 위해 논리 주소를 만들고 메모리 관리 장치(memory management unit,MMU)를 통해 물리 주소로 변환하여 사용한다.

### 연속 메모리 할당
- 프로세스가 연속된 주소로 메모리에 할당되고 종료되는 것을 반복하다 보면 프로세스의 다양한 크기로 인해 빈 메모리 블록인 hole이 생성된다.
- 남아있는 hole 중 어느 위치에 프로세스를 올리냐에 따라 메모리의 효율성이 달라진다.
    1. 최초 적합
        - 제일 처음 찾은 가용 공간에 프로세스를 할당한다.
    2. 최적 적합
        - 프로세스가 사용 가능한 공간 중 가장 작은 것을 택한다.
    3. 최악 적합
        - 가장 큰 가용 공간을 선택한다.
- 모의 실험을 통해 최초 적합과 최적 적합이 시간과 메모리 이용 효율 측면에서 최악 적합보다 좋다는 것이 입증되었다.

### 단편화

#### 외부 단편화
- 최초 적합, 최적 적합 전략 모두 외부 단편화를 발생시킨다.
- 프로세스들의 적재, 제거를 반복하다보면 프로세스들을 실행할 수 없는 작은 공간들이 여러 군데 발생한다.
- 메모리의 모든 내용을 한군데로 몰아 압축할 수도 있지만 주소를 동적으로 재배치할 수 있을 때만 가능하고 이마저도 비용이 많이 발생한다.

#### 내부 단편화
- 프로세스를 메모리에 할당할 때 정확히 프로세스의 크기만큼 메모리에 할당하는 것이 아닌 일정한 크기 단위로 할당을 한다.
- 프로세스의 크기가 할당 크기 단위의 배수가 아니라면 남는 메모리 공간이 발생한다.

### 세그먼트(Segment)
- 가상 메모리를 서로 다른 단위인 세그먼트로 나눈 후 물리 메모리에 할당하는 기법으로 내부 단편화를 해결하는데 사용할 수 있다. 하지만 외부 단편화를 해결하지는 못한다.

### 페이징
![image](https://user-images.githubusercontent.com/63232876/163589331-96fcd3cc-4d4f-41c4-968a-adfb67859f14.png)
https://www2.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/8_MainMemory.html
- 외부 단편화를 해결하기 위해 프로세스를 연속적인 물리 주소 공간에 할당하지 않고 물리 메모리에는 프레임, 논리 메모리에는 페이지라는 단위로 나눠 저장한다.
- 논리 주소는 페이지 번호와 페이지 오프셋으로 나누어진다. 페이지 번호는 물리 메모리의 프레임와 대응되어있는 페이지 테이블에서의 위치를 나타내고 페이지 오프셋은 프레임 안에서의 위치를 나타낸다.
- 페이지 크기가 커지면 내부 단편화가 커지고, 페이지 크기가 작아지면 페이지 테이블의 용량이 커지며 관리가 어려워진다.

#### 문제점
- 물리 메모리에 접근을 하기 위해서는 페이지 테이블과 물리 메모리, 두 번의 메모리 접근이 필요하고 결국 시간이 지연된다.
    - Translation Look-aside Buffers(TLB)
    ![image](https://user-images.githubusercontent.com/63232876/163589274-be879984-f1a7-4581-9733-3a1f757fd6dd.png)
    https://www2.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/8_MainMemory.html
        - 소형 하드웨어 캐시로 페이지 번호와 프레임 번호를 저장한 후 논리 주소의 페이지 번호를 병렬로 검색해 페이지 번호가 존재하면(TLB hit) 바로 메모리에 접근한다.
        - TLB에 페이지 번호가 없으면(TLB miss) 페이지 테이블로 접근한다.
- 페이지 테이블이 커지면 페이지 테이블 역시 메모리에 할당되므로 메모리에 연속적으로 할당되는 크기 역시 커진다. 페이징을 사용하면서 연속적인 주소의 큰 공간을 할당해야 한다는 모순이 발생한다.
    1. 계층적 페이징
        - 페이지 테이블을 다시 페이징하여 공간을 나눈다.
        - 일반적인 64비트 주소에서는 많은 계층이 필요하여 각 계층 접근하는데 많은 시간이 소요된다.
    2. 해시 페이지 테이블
        - 주소 공간이 32비트보다 커지면 논리 주소를 해시로 사용하는 해시 페이지 테이블을 많이 사용한다.
        - 각 원소는 페이지 번호, 페이지 오프셋, 다음 원소 포인터를 가진다.

#### 스와핑(Swapping)
- 메모리에는 프로세스가 온전히 필요로하는 용량보다 더 적은 공간이 할당된다. 할당되지 않은 데이터는 보조저장장치에 있는데 이를 메모리로 옮기기 위해 스와핑을 한다.
- 스와핑은 프로세스 단위가 아닌 페이지 단위로 이루어진다.
- 메모리에서 보조저장장치로 옮기는 것을 스왑아웃, 그 반대는 스왑인이라고 한다.

## 가상 메모리
- 가상 메모리는 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이다. 이 기법의 장점은 사용자 프로그램이 물리 메모리보다 커져도 된다는 점이다.

### 요구 페이징(Demand Paging)
- 프로세스 초기 실행 시 프로그램 전체가 메모리에 있을 필요는 없다. 필요한 부분만 페이지 단위로 메모리에 적재하는 기법을 요구 페이징이라고 한다.
- 페이지 테이블의 유효-무효(valid-invalid) 비트를 확인하여 유효로 설정되어있으면 해당 페이지가 메모리에 존재하고 무효로 설정되어 있으면 메모리에 해당 페이지가 적재되어있지 않다는 의미이다.

    #### 페이지 폴트 처리 과정
    1. 페이지 테이블을 참조하여 무효한 테이블임을 확인한다.
    2. 트랩으로 해당 프로세스는 중단된다.
    3. 페이지 참조가 유효한 것인지 확인한다. 만약 그렇지 않으면 프로세스는 중단(abort)된다.
    4. 보조저장장치의 해당 페이지를 메모리에 적재하고 페이지 테이블을 수정한다.
    5. 트랩에 의해 중단되었던 명령을 다시 수행한다. 해당 페이지가 메모리에 적재되어서 정상적인 동작이 가능해진다.

### 쓰기 시 복사(Copy on Write)
- fork() 시스템 콜을 사용하면 부모 프로세스와 똑같은 자식 프로세스를 생성한다. 부모 프로세스와 자식 프로세스가 같은 페이지를 공유하게 하고 자식 프로세스가 공유 중인 페이지에 쓰기를 할 때, 새 페이지에 복사하여 쓰도록 한다.
- 필요한 페이지만 생성하기 때문에 프로세스 생성시간, 페이지 수를 줄일 수 있다.

### 페이지 교체
- 페이지 폴트 시 메모리에 free frame이 없으면 페이지를 교체해야한다. 스와핑은 오버헤드를 발생시키므로 페이지 폴트가 일어나지 않게 페이지를 고르는 것이 중요하다.
    1. FIFO 페이지 교체
        - 먼저 할당된 페이지를 먼저 교체하는 전략이다.
        - 간단하지만 페이지의 이용 빈도를 고려하지 않으므로 효율적이지 않다.
    2. 최적 페이지 교체
        - 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체한다.
        - 가장 낮은 페이지 폴트를 보여주지만 앞으로 메모리를 어떻게 참조할지는 알기 어렵기 때문에 구현은 어렵다.
    3. LRU 페이지 교체(least recently used)
        - 미래 대신 과거 접근 시간에 근거하여 페이지를 교체한다.
        - counter를 사용하여 가장 접근 빈도가 낮은 페이지를 선택하거나, stack을 사용하여 접근한 페이지를 stack의 맨 위로 올리는 방법이 가능하다.
    4. LRU 근사 페이지 교채
        - 항상 정확한 값을 유지하는 것은 효율이 떨어질 수도 있고 하드웨어가 해당 방법을 충분히 지원하지 않을 수 있다.
        - 페이지 접근을 비트로 나타내서 해당 페이지의 대략적인 접근 시간 및 빈도를 알 수 있다.

- 프로세스 수행 과정에서 매번 페이지 폴트가 나면 시스템의 성능이 저하될 수도 있다. 다행히 프로세스를 분석해 보면 참소의 지역성으로 인해 요구 페이징은 만족할 만한 성능을 보인다.

### 스레싱(Thrashing)
- 메모리에 충분한 프레임이 없다면 페이지 폴트는 증가한다. 스와핑으로 인한 CPU 이용률의 저하가 발생하고 CPU 스케줄러는 이를 해결하기 위해 멀티 프로그래밍 정도를 높인다. 하지만 새 프로세스로 인해 더 많은 페이지 폴트를 야기하는 악순환이 반복된다. 이렇게 발생하는 과도한 페이징 작업을 스레싱이라고 한다.
- 이를 해결하기 위해서는 페이지 교체 알고리즘을 바꾸거나 멀티 프로그래밍의 정도를 낮춰야 한다.


